{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shahanas2003/gen_ai/blob/main/High_Resolution_Image_Enhancement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xo7gkhJ5eDDx",
        "outputId": "1ebdd63a-c3a7-4241-f20d-ad825fde2d04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (0.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (1.16.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2025.10.16)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Collecting git+https://github.com/sberbank-ai/Real-ESRGAN.git\n",
            "  Cloning https://github.com/sberbank-ai/Real-ESRGAN.git to /tmp/pip-req-build-4p7uthjr\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/sberbank-ai/Real-ESRGAN.git /tmp/pip-req-build-4p7uthjr\n",
            "  Resolved https://github.com/sberbank-ai/Real-ESRGAN.git to commit 362a0316878f41dbdfbb23657b450c3353de5acf\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from RealESRGAN==1.0) (2.0.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from RealESRGAN==1.0) (4.12.0.88)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from RealESRGAN==1.0) (11.3.0)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.12/dist-packages (from RealESRGAN==1.0) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from RealESRGAN==1.0) (0.23.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from RealESRGAN==1.0) (4.67.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (from RealESRGAN==1.0) (0.35.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.7->RealESRGAN==1.0) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7->RealESRGAN==1.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.7->RealESRGAN==1.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7->RealESRGAN==1.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.7->RealESRGAN==1.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7->RealESRGAN==1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.7->RealESRGAN==1.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7->RealESRGAN==1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7->RealESRGAN==1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7->RealESRGAN==1.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7->RealESRGAN==1.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7->RealESRGAN==1.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7->RealESRGAN==1.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7->RealESRGAN==1.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7->RealESRGAN==1.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7->RealESRGAN==1.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7->RealESRGAN==1.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7->RealESRGAN==1.0) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7->RealESRGAN==1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7->RealESRGAN==1.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7->RealESRGAN==1.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7->RealESRGAN==1.0) (3.4.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->RealESRGAN==1.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->RealESRGAN==1.0) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->RealESRGAN==1.0) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->RealESRGAN==1.0) (1.1.10)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.7->RealESRGAN==1.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.7->RealESRGAN==1.0) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->RealESRGAN==1.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->RealESRGAN==1.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->RealESRGAN==1.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->RealESRGAN==1.0) (2025.10.5)\n",
            "Building wheels for collected packages: RealESRGAN\n",
            "  Building wheel for RealESRGAN (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for RealESRGAN: filename=RealESRGAN-1.0-py3-none-any.whl size=9103 sha256=32f522a32582758ce1709bf352bdabff9bf4493599271cf6d1f16c605a6c9f4a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-cskmhc5y/wheels/56/5d/e9/27a6e9a12fdf8f374427c68f494d54640406e56632a6c2835d\n",
            "Successfully built RealESRGAN\n",
            "Installing collected packages: RealESRGAN\n",
            "Successfully installed RealESRGAN-1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch Pillow numpy scikit-image\n",
        "!pip install git+https://github.com/sberbank-ai/Real-ESRGAN.git\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision\n"
      ],
      "metadata": {
        "id": "-s2KsvfUrIYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_files = os.listdir(root_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.root_dir, self.image_files[idx])\n",
        "        image = Image.open(img_name)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image"
      ],
      "metadata": {
        "id": "zaoaacj-rVfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class RRDB(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(RRDB, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
        "        self.relu = nn.LeakyReLU(0.2, inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.relu(self.conv1(x))\n",
        "        out = self.relu(self.conv2(out))\n",
        "        out = self.conv3(out)\n",
        "        return x + out  # Residual connection\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, in_channels=3, num_rrdb=23):\n",
        "        super(Generator, self).__init__()\n",
        "        self.initial_conv = nn.Conv2d(in_channels, 64, kernel_size=3, padding=1)\n",
        "        self.rrdb_blocks = nn.Sequential(*[RRDB(64) for _ in range(num_rrdb)])\n",
        "        self.final_conv = nn.Conv2d(64, in_channels, kernel_size=3, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        initial_feature = self.initial_conv(x)\n",
        "        out = self.rrdb_blocks(initial_feature)\n",
        "        out = self.final_conv(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "m9vdn0PirrdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_channels=3):\n",
        "        super(Discriminator, self).__init__()\n",
        "        def block(in_feat, out_feat, normalize=True):\n",
        "            layers = [nn.Conv2d(in_feat, out_feat, 4, stride=2, padding=1)]\n",
        "            if normalize:\n",
        "                layers.append(nn.BatchNorm2d(out_feat))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            return layers\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *block(in_channels, 64, normalize=False),\n",
        "            *block(64, 128),\n",
        "            *block(128, 256),\n",
        "            *block(256, 512),\n",
        "            nn.Conv2d(512, 1, 3, stride=1, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        return self.model(img)"
      ],
      "metadata": {
        "id": "shTjshCKrt_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class ContentLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ContentLoss, self).__init__()\n",
        "\n",
        "    def forward(self, sr, hr):\n",
        "        return F.mse_loss(sr, hr)\n",
        "\n",
        "class PerceptualLoss(nn.Module):\n",
        "    def __init__(self, vgg_model):\n",
        "        super(PerceptualLoss, self).__init__()\n",
        "        self.vgg = vgg_model.features[:36]  # Use pre-trained VGG features\n",
        "        self.vgg.eval()\n",
        "\n",
        "    def forward(self, sr, hr):\n",
        "        sr_features = self.vgg(sr)\n",
        "        hr_features = self.vgg(hr)\n",
        "        return F.mse_loss(sr_features, hr_features)"
      ],
      "metadata": {
        "id": "8mvv6eC-rwFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(generator, discriminator, dataloader, num_epochs, optimizer_G, optimizer_D, criterion_content, criterion_perceptual):\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, img in enumerate(dataloader):\n",
        "            # Train Generator\n",
        "            optimizer_G.zero_grad()\n",
        "            sr_image = generator(img)\n",
        "            content_loss = criterion_content(sr_image, img)\n",
        "            perceptual_loss = criterion_perceptual(sr_image, img)\n",
        "            g_loss = content_loss + perceptual_loss\n",
        "            g_loss.backward()\n",
        "            optimizer_G.step()\n",
        "\n",
        "            # Train Discriminator\n",
        "            optimizer_D.zero_grad()\n",
        "            real_output = discriminator(img)\n",
        "            fake_output = discriminator(sr_image.detach())\n",
        "            d_loss = F.binary_cross_entropy_with_logits(real_output, torch.ones_like(real_output)) + \\\n",
        "                     F.binary_cross_entropy_with_logits(fake_output, torch.zeros_like(fake_output))\n",
        "            d_loss.backward()\n",
        "            optimizer_D.step()\n",
        "\n",
        "            if i % 10 == 0:\n",
        "                print(f\"Epoch {epoch}/{num_epochs}, Step {i}, G Loss: {g_loss.item()}, D Loss: {d_loss.item()}\")"
      ],
      "metadata": {
        "id": "G2jNl3Elryfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def upscale_image(generator, lr_image):\n",
        "    generator.eval()\n",
        "    with torch.no_grad():\n",
        "        sr_image = generator(lr_image)\n",
        "    return sr_image"
      ],
      "metadata": {
        "id": "E0aun5qbr1O1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from torchvision.utils import save_image"
      ],
      "metadata": {
        "id": "rwGwb351r3j1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/BSDS300-images.tgz\n",
        "!tar -xvzf BSDS300-images.tgz\n"
      ],
      "metadata": {
        "id": "zzd32LY7u3tj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dataset class for loading and preprocessing images\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_files = os.listdir(root_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.root_dir, self.image_files[idx])\n",
        "        image = Image.open(img_name).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image\n",
        "\n",
        "# Define transforms (resize images for simplicity)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Create Dataset and DataLoader\n",
        "dataset = ImageDataset(root_dir=\"BSDS300/images/train\", transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)"
      ],
      "metadata": {
        "id": "mA2_eOPXr7ZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RRDB(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(RRDB, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
        "        self.relu = nn.LeakyReLU(0.2, inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.relu(self.conv1(x))\n",
        "        out = self.relu(self.conv2(out))\n",
        "        out = self.conv3(out)\n",
        "        return x + out  # Residual connection\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, in_channels=3, num_rrdb=23):\n",
        "        super(Generator, self).__init__()\n",
        "        self.initial_conv = nn.Conv2d(in_channels, 64, kernel_size=3, padding=1)\n",
        "        self.rrdb_blocks = nn.Sequential(*[RRDB(64) for _ in range(num_rrdb)])\n",
        "        self.final_conv = nn.Conv2d(64, in_channels, kernel_size=3, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        initial_feature = self.initial_conv(x)\n",
        "        out = self.rrdb_blocks(initial_feature)\n",
        "        out = self.final_conv(out)\n",
        "        return out\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_channels=3):\n",
        "        super(Discriminator, self).__init__()\n",
        "        def block(in_feat, out_feat, normalize=True):\n",
        "            layers = [nn.Conv2d(in_feat, out_feat, 4, stride=2, padding=1)]\n",
        "            if normalize:\n",
        "                layers.append(nn.BatchNorm2d(out_feat))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            return layers\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *block(in_channels, 64, normalize=False),\n",
        "            *block(64, 128),\n",
        "            *block(128, 256),\n",
        "            *block(256, 512),\n",
        "            nn.Conv2d(512, 1, 3, stride=1, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        return self.model(img)"
      ],
      "metadata": {
        "id": "oUaF0JLTvEJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ContentLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ContentLoss, self).__init__()\n",
        "\n",
        "    def forward(self, sr, hr):\n",
        "        return F.mse_loss(sr, hr)\n",
        "\n",
        "class PerceptualLoss(nn.Module):\n",
        "    def __init__(self, vgg_model):\n",
        "        super(PerceptualLoss, self).__init__()\n",
        "        self.vgg = vgg_model.features[:36]  # Use pre-trained VGG features\n",
        "        self.vgg.eval()\n",
        "\n",
        "    def forward(self, sr, hr):\n",
        "        sr_features = self.vgg(sr)\n",
        "        hr_features = self.vgg(hr)\n",
        "        return F.mse_loss(sr_features, hr_features)"
      ],
      "metadata": {
        "id": "3Tx131iivHPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(generator, discriminator, dataloader, num_epochs, optimizer_G, optimizer_D, criterion_content, criterion_perceptual, device):\n",
        "    generator.to(device)\n",
        "    discriminator.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, img in enumerate(dataloader):\n",
        "            img = img.to(device)\n",
        "\n",
        "            # Generate super-resolved image\n",
        "            sr_image = generator(img)\n",
        "\n",
        "            # Train Generator\n",
        "            optimizer_G.zero_grad()\n",
        "            content_loss = criterion_content(sr_image, img)\n",
        "            perceptual_loss = criterion_perceptual(sr_image, img)\n",
        "            g_loss = content_loss + perceptual_loss\n",
        "            g_loss.backward()\n",
        "            optimizer_G.step()\n",
        "\n",
        "            # Train Discriminator\n",
        "            optimizer_D.zero_grad()\n",
        "            real_output = discriminator(img)\n",
        "            fake_output = discriminator(sr_image.detach())\n",
        "            d_loss = F.binary_cross_entropy_with_logits(real_output, torch.ones_like(real_output)) + \\\n",
        "                     F.binary_cross_entropy_with_logits(fake_output, torch.zeros_like(fake_output))\n",
        "            d_loss.backward()\n",
        "            optimizer_D.step()\n",
        "\n",
        "            if i % 10 == 0:\n",
        "                print(f\"Epoch {epoch}/{num_epochs}, Step {i}, G Loss: {g_loss.item()}, D Loss: {d_loss.item()}\")"
      ],
      "metadata": {
        "id": "amEWn_sMvKgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize Generator, Discriminator, and Optimizers\n",
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002)\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
        "\n",
        "# Load pre-trained VGG model for Perceptual Loss\n",
        "vgg = models.vgg19(pretrained=True).to(device)\n",
        "criterion_content = ContentLoss()\n",
        "criterion_perceptual = PerceptualLoss(vgg)\n",
        "\n",
        "# Train ESRGAN\n",
        "train(generator, discriminator, dataloader, num_epochs=2, optimizer_G=optimizer_G, optimizer_D=optimizer_D,\n",
        "      criterion_content=criterion_content, criterion_perceptual=criterion_perceptual, device=device)"
      ],
      "metadata": {
        "id": "sSf8nkVBvSPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a test image\n",
        "test_image = Image.open(\"BSDS300/images/test/100075.jpg\").convert(\"RGB\")\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "test_image = transform(test_image).unsqueeze(0).to(device)\n",
        "\n",
        "# Generate super-resolved image\n",
        "generator.eval()\n",
        "with torch.no_grad():\n",
        "    sr_image = generator(test_image)\n",
        "\n",
        "# Save and Display Results\n",
        "save_image(sr_image, \"sr_image.png\")\n",
        "save_image(test_image, \"lr_image.png\")\n",
        "\n",
        "# Show images\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Low-Resolution Image\")\n",
        "plt.imshow(np.transpose(test_image.squeeze().cpu().numpy(), (1, 2, 0)))\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Super-Resolved Image\")\n",
        "plt.imshow(np.transpose(sr_image.squeeze().cpu().numpy(), (1, 2, 0)))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gcJX88LhvdeD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}